{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from srai.joiners import IntersectionJoiner\n",
    "from srai.loaders.osm_loaders.filters import GEOFABRIK_LAYERS\n",
    "from srai.plotting import plot_regions\n",
    "from srai.regionalizers import S2Regionalizer, geocode_to_region_gdf\n",
    "\n",
    "area_gdf = geocode_to_region_gdf(\"Grand Est\")\n",
    "plot_regions(area_gdf, tiles_style=\"CartoDB positron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c95094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image regions: 34\n"
     ]
    }
   ],
   "source": [
    "img_resolution = 8\n",
    "patch_resolution = 12\n",
    "\n",
    "img_regionalizer = S2Regionalizer(resolution=img_resolution, buffer=False)\n",
    "img_s2_regions = img_regionalizer.transform(area_gdf.reset_index(drop=True))\n",
    "\n",
    "img_s2_geometry = img_s2_regions.union_all()\n",
    "\n",
    "print(\"Image regions:\", len(img_s2_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regions(\n",
    "    img_s2_regions,\n",
    "    tiles_style=\"CartoDB positron\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f596bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from srai.embedders.count_embedder import CountEmbedder\n",
    "from srai.embedders.s2vec.dataset import S2VecDataset\n",
    "from srai.embedders.s2vec.s2_utils import get_patches_from_img_gdf\n",
    "from srai.loaders.osm_loaders.osm_pbf_loader import OSMPbfLoader\n",
    "\n",
    "tags = GEOFABRIK_LAYERS\n",
    "loader = OSMPbfLoader()\n",
    "joiner = IntersectionJoiner()\n",
    "\n",
    "preproc_batch_size = 1\n",
    "\n",
    "# arrays = []\n",
    "data = pd.DataFrame()\n",
    "img_patch_joint_gdf = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(0, len(img_s2_regions), preproc_batch_size):\n",
    "    batch = img_s2_regions.iloc[i:i + preproc_batch_size]\n",
    "    print(f\"Processing batch {i // preproc_batch_size + 1} of {len(img_s2_regions) // preproc_batch_size + 1}\")\n",
    "    batch_features_gdf = loader.load(batch, tags)\n",
    "    patches_gdf, batch_img_patch_joint_gdf = get_patches_from_img_gdf(\n",
    "    img_gdf=batch, target_level=patch_resolution\n",
    "    )\n",
    "    joiner = IntersectionJoiner()\n",
    "    patch_feature_joint_gdf = joiner.transform(patches_gdf, batch_features_gdf)\n",
    "    count_embedder = CountEmbedder(GEOFABRIK_LAYERS)\n",
    "    counts_df = count_embedder.transform(patches_gdf, batch_features_gdf, patch_feature_joint_gdf)\n",
    "    data = pd.concat([data, counts_df])\n",
    "    img_patch_joint_gdf = pd.concat([img_patch_joint_gdf, batch_img_patch_joint_gdf])\n",
    "    # arrays.append(count_embedder.transform(patches_gdf, batch_features_gdf, patch_feature_joint_gdf).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca1ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 5524.17it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = S2VecDataset(data=data, img_patch_joint_gdf=img_patch_joint_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8b58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split sizes\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = len(ds) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_ds, val_ds = random_split(ds, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders with optimized settings\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,   # Increase if your system supports it\n",
    "    pin_memory=True  # Enable if using CUDA\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0240f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from srai.embedders.s2vec import S2VecModel\n",
    "\n",
    "model = S2VecModel(\n",
    "    img_size=16,\n",
    "    patch_size=1,\n",
    "    in_ch=347,\n",
    "    lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f138e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import wandb\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"s2vec-embedding\")\n",
    "early_stopping = EarlyStopping(monitor=\"validation_loss\", patience=5, mode=\"min\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# To start training:\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
